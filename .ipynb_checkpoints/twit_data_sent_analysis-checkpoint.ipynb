{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3620cf38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data file path.\n",
      "File path generation completed.\n",
      "/home/nuclear/Stuff/PythonPrograms/Twitter-Portfolio-Project/data/test.jsonuk\n",
      "Loading Roberta and autokenizer.\n",
      "Roberta and autotokenizer loaded.\n",
      "Converting file to dataframe.\n",
      "File to dataframe conversion completed.\n",
      "Generating data file path.\n",
      "File path generation completed.\n",
      "Calculating and recording tweet sentiment score.\n",
      "{'tweet_id': '1567151913602269184', 'negative_score': '0.022226034', 'neutral_score': '0.33841527', 'positive_score': '0.6393587'}\n",
      "{'tweet_id': '1567151655560388608', 'negative_score': '0.4399557', 'neutral_score': '0.52734315', 'positive_score': '0.03270108'}\n",
      "{'tweet_id': '1567151271232110594', 'negative_score': '0.11765074', 'neutral_score': '0.7982512', 'positive_score': '0.08409795'}\n",
      "{'tweet_id': '1567150906902208513', 'negative_score': '0.39192396', 'neutral_score': '0.58538103', 'positive_score': '0.022694923'}\n",
      "{'tweet_id': '1567150877508501505', 'negative_score': '0.89643264', 'neutral_score': '0.09892842', 'positive_score': '0.0046389257'}\n",
      "{'tweet_id': '1567150757828329477', 'negative_score': '0.34242743', 'neutral_score': '0.5831487', 'positive_score': '0.0744238'}\n",
      "{'tweet_id': '1567150677910032385', 'negative_score': '0.8741989', 'neutral_score': '0.120704435', 'positive_score': '0.005096508'}\n",
      "{'tweet_id': '1567150668057559041', 'negative_score': '0.8450514', 'neutral_score': '0.1377006', 'positive_score': '0.017248083'}\n",
      "{'tweet_id': '1567150667013267458', 'negative_score': '0.8450514', 'neutral_score': '0.1377006', 'positive_score': '0.017248083'}\n",
      "{'tweet_id': '1567150665364824066', 'negative_score': '0.8450514', 'neutral_score': '0.1377006', 'positive_score': '0.017248083'}\n",
      "{'tweet_id': '1567150665339633664', 'negative_score': '0.8450514', 'neutral_score': '0.1377006', 'positive_score': '0.017248083'}\n",
      "{'tweet_id': '1567150665297805314', 'negative_score': '0.8450514', 'neutral_score': '0.1377006', 'positive_score': '0.017248083'}\n",
      "{'tweet_id': '1567149608316407808', 'negative_score': '0.4553591', 'neutral_score': '0.46393567', 'positive_score': '0.080705255'}\n",
      "{'tweet_id': '1567148111935713282', 'negative_score': '0.66416186', 'neutral_score': '0.31124452', 'positive_score': '0.024593651'}\n",
      "{'tweet_id': '1567147811392884736', 'negative_score': '0.94291764', 'neutral_score': '0.053741865', 'positive_score': '0.003340705'}\n",
      "{'tweet_id': '1567146990550532104', 'negative_score': '0.7260178', 'neutral_score': '0.25948867', 'positive_score': '0.014493444'}\n",
      "{'tweet_id': '1567145952015695879', 'negative_score': '0.8165462', 'neutral_score': '0.17414424', 'positive_score': '0.009309706'}\n",
      "{'tweet_id': '1567145616462995459', 'negative_score': '0.15336312', 'neutral_score': '0.8029576', 'positive_score': '0.043679204'}\n",
      "{'tweet_id': '1567144139447308290', 'negative_score': '0.5379667', 'neutral_score': '0.4104052', 'positive_score': '0.05162817'}\n",
      "{'tweet_id': '1567144048120532992', 'negative_score': '0.3892123', 'neutral_score': '0.5514109', 'positive_score': '0.059376862'}\n",
      "{'tweet_id': '1567143772223406083', 'negative_score': '0.1537961', 'neutral_score': '0.76649445', 'positive_score': '0.07970946'}\n",
      "{'tweet_id': '1567143199285592064', 'negative_score': '0.7575251', 'neutral_score': '0.23270679', 'positive_score': '0.009768084'}\n",
      "{'tweet_id': '1567142933467365379', 'negative_score': '0.043388005', 'neutral_score': '0.87226784', 'positive_score': '0.08434421'}\n",
      "{'tweet_id': '1567142181210853377', 'negative_score': '0.8601578', 'neutral_score': '0.125582', 'positive_score': '0.014260194'}\n",
      "{'tweet_id': '1567141748966555651', 'negative_score': '0.2541408', 'neutral_score': '0.5806291', 'positive_score': '0.16523'}\n",
      "{'tweet_id': '1567140890661064705', 'negative_score': '0.02032803', 'neutral_score': '0.80429965', 'positive_score': '0.17537247'}\n",
      "{'tweet_id': '1567140528252125186', 'negative_score': '0.018727055', 'neutral_score': '0.7055791', 'positive_score': '0.27569404'}\n",
      "{'tweet_id': '1567140182708699138', 'negative_score': '0.39898184', 'neutral_score': '0.5624946', 'positive_score': '0.038523488'}\n",
      "{'tweet_id': '1567140139956043776', 'negative_score': '0.05865433', 'neutral_score': '0.62983024', 'positive_score': '0.31151548'}\n",
      "{'tweet_id': '1567140035899580416', 'negative_score': '0.1511003', 'neutral_score': '0.79781103', 'positive_score': '0.05108865'}\n",
      "Tweet sentiment score calculated and recorded.\n",
      "/home/nuclear/Stuff/PythonPrograms/Twitter-Portfolio-Project/data/test_sentiment.jsonuk\n",
      "Converting file to dataframe.\n",
      "File to dataframe conversion completed.\n",
      "Generating data file path.\n",
      "File path generation completed.\n",
      "Generating data file path.\n",
      "File path generation completed.\n",
      "----------------------------------------\n",
      "               tweet_id                                         tweet_text  \\\n",
      "0   1567151913602269184  https://t.co/OuIxTYJjsQ\\nAlways good to get im...   \n",
      "1   1567151655560388608  ðŸ©¸ After Roe v. Wade was overturned, US women s...   \n",
      "2   1567151271232110592  With the overturning of Roe v Wade we will be ...   \n",
      "3   1567150906902208512  Pro-Lifers cite Christianity to explain anti-a...   \n",
      "4   1567150877508501504  The United States is a global outlier for abor...   \n",
      "5   1567150757828329472  Since the U.S. Supreme Court overturn Roe v. W...   \n",
      "6   1567150677910032384  If you were a known abortionist before â€œRoe,â€ ...   \n",
      "7   1567150668057559040  \"Iâ€™m a law professor and even I am struggling ...   \n",
      "8   1567150667013267456  \"Iâ€™m a law professor and even I am struggling ...   \n",
      "9   1567150665364824064  \"Iâ€™m a law professor and even I am struggling ...   \n",
      "10  1567150665339633664  \"Iâ€™m a law professor and even I am struggling ...   \n",
      "11  1567150665297805312  \"Iâ€™m a law professor and even I am struggling ...   \n",
      "12  1567149608316407808  This summer, thousands turned up with @DSACinc...   \n",
      "13  1567148111935713280  A new survey from the Pew Research Center find...   \n",
      "14  1567147811392884736  ECTOPIC  PREGNANCY \\nthanks to the Hawleys who...   \n",
      "15  1567146990550532096  Jennifer Lawrence on Roe v Wade Overturn: Poli...   \n",
      "16  1567145952015695872  Jennifer Lawrence Blasts Two-Party System Amid...   \n",
      "17  1567145616462995456  Yâ€™a une meuf sur TT qui raconte comment Ã  lâ€™au...   \n",
      "18  1567144139447308288  Moral entrepreneurs changing laws reminds me o...   \n",
      "19  1567144048120532992  Democrats have over-performed in every special...   \n",
      "20  1567143772223406080  New: @JoshShapiroPAâ€™s campaign released two ne...   \n",
      "21  1567143199285592064  US President Joe Biden signs order on abortion...   \n",
      "22  1567142933467365376  Top story: Jennifer Lawrence Talks Motherhood,...   \n",
      "23  1567142181210853376  To ALL Americans:\\nInflation, jobs, Roe v Wade...   \n",
      "24  1567141748966555648  The GOP has made it crystal clear: Overturning...   \n",
      "25  1567140890661064704  In a no-holdâ€™s-barred interview for Vogueâ€™s Oc...   \n",
      "26  1567140528252125184  Loving Jesus Style: Roe v Wade What Now https:...   \n",
      "27  1567140182708699136  [Premiering 9/6 at 1PM ET] Establishment Democ...   \n",
      "28  1567140139956043776  Loving Jesus Style: Roe v Wade   Winners? Lose...   \n",
      "29  1567140035899580416  Roe v. Wade has been gone for only a matter of...   \n",
      "\n",
      "                  tweet_time      tweet_author_id tweet_language  \\\n",
      "0  2022-09-06 14:05:07+00:00            724633794             en   \n",
      "1  2022-09-06 14:04:05+00:00            252751061             en   \n",
      "2  2022-09-06 14:02:33+00:00             28863408             en   \n",
      "3  2022-09-06 14:01:07+00:00  1329506226900754434             en   \n",
      "4  2022-09-06 14:01:00+00:00  1109933379217252353             en   \n",
      "5  2022-09-06 14:00:31+00:00             14437914             en   \n",
      "6  2022-09-06 14:00:12+00:00             82689705             en   \n",
      "7  2022-09-06 14:00:10+00:00             24878216             en   \n",
      "8  2022-09-06 14:00:09+00:00             10685542             en   \n",
      "9  2022-09-06 14:00:09+00:00           2149414262             en   \n",
      "10 2022-09-06 14:00:09+00:00             18169582             en   \n",
      "11 2022-09-06 14:00:09+00:00             14095883             en   \n",
      "12 2022-09-06 13:55:57+00:00   821892571576279040             en   \n",
      "13 2022-09-06 13:50:00+00:00             20545835             en   \n",
      "14 2022-09-06 13:48:49+00:00   875324076230922242             en   \n",
      "15 2022-09-06 13:45:33+00:00            198306835             en   \n",
      "16 2022-09-06 13:41:25+00:00             13992132             en   \n",
      "17 2022-09-06 13:40:05+00:00           2778227002             fr   \n",
      "18 2022-09-06 13:34:13+00:00  1481062557729312772             en   \n",
      "19 2022-09-06 13:33:51+00:00  1087380412089987077             en   \n",
      "20 2022-09-06 13:32:46+00:00            307885277             en   \n",
      "21 2022-09-06 13:30:29+00:00  1548014239884816387             en   \n",
      "22 2022-09-06 13:29:26+00:00           1276324501             en   \n",
      "23 2022-09-06 13:26:26+00:00             50502359             en   \n",
      "24 2022-09-06 13:24:43+00:00  1484313372934156290             en   \n",
      "25 2022-09-06 13:21:19+00:00            136361303             en   \n",
      "26 2022-09-06 13:19:52+00:00           1519990998             en   \n",
      "27 2022-09-06 13:18:30+00:00  1557070082496405504             en   \n",
      "28 2022-09-06 13:18:20+00:00           1519990998             en   \n",
      "29 2022-09-06 13:17:55+00:00  1557648186319048704             en   \n",
      "\n",
      "    retweet_count  reply_count  like_count  quote_count  \\\n",
      "0               0            0           0            0   \n",
      "1               1            0           1            0   \n",
      "2               0            0           0            0   \n",
      "3               0            0           0            0   \n",
      "4               0            0           0            0   \n",
      "5               0            0           7            1   \n",
      "6               0            0           0            0   \n",
      "7               0            0           0            0   \n",
      "8               0            0           1            0   \n",
      "9               0            0           0            0   \n",
      "10              0            0           0            0   \n",
      "11              0            0           0            0   \n",
      "12              2            0           2            0   \n",
      "13              2           36          18            2   \n",
      "14              0            0           0            0   \n",
      "15              0            0           0            0   \n",
      "16              0            0          47            5   \n",
      "17              0            0           0            0   \n",
      "18              0            0           0            0   \n",
      "19             18           41          68           10   \n",
      "20             10            0          20            0   \n",
      "21              0            0           0            0   \n",
      "22              0            0           0            0   \n",
      "23              0            0           0            0   \n",
      "24              0            0           0            0   \n",
      "25             23            2         161            4   \n",
      "26              0            0           0            0   \n",
      "27              0            0           0            0   \n",
      "28              0            0           0            0   \n",
      "29              0            0           0            0   \n",
      "\n",
      "                 tweet_source  negative_score  neutral_score  positive_score  \\\n",
      "0             Twitter Web App        0.022226       0.338415        0.639359   \n",
      "1                  SocialFlow        0.439956       0.527343        0.032701   \n",
      "2          Twitter for iPhone        0.117651       0.798251        0.084098   \n",
      "3                  Zapier.com        0.391924       0.585381        0.022695   \n",
      "4   Semrush Social Media Tool        0.896433       0.098928        0.004639   \n",
      "5               Sprout Social        0.342427       0.583149        0.074424   \n",
      "6                     Echobox        0.874199       0.120704        0.005097   \n",
      "7              SocialNewsDesk        0.845051       0.137701        0.017248   \n",
      "8              SocialNewsDesk        0.845051       0.137701        0.017248   \n",
      "9              SocialNewsDesk        0.845051       0.137701        0.017248   \n",
      "10             SocialNewsDesk        0.845051       0.137701        0.017248   \n",
      "11             SocialNewsDesk        0.845051       0.137701        0.017248   \n",
      "12         Twitter for iPhone        0.455359       0.463936        0.080705   \n",
      "13                    Emplifi        0.664162       0.311245        0.024594   \n",
      "14            Twitter Web App        0.942918       0.053742        0.003341   \n",
      "15              WordPress.com        0.726018       0.259489        0.014493   \n",
      "16            Twitter Web App        0.816546       0.174144        0.009310   \n",
      "17         Twitter for iPhone        0.153363       0.802958        0.043679   \n",
      "18         Twitter for iPhone        0.537967       0.410405        0.051628   \n",
      "19       Twitter Media Studio        0.389212       0.551411        0.059377   \n",
      "20         Twitter for iPhone        0.153796       0.766494        0.079709   \n",
      "21            Twitter Web App        0.757525       0.232707        0.009768   \n",
      "22          The Tweeted Times        0.043388       0.872268        0.084344   \n",
      "23        Twitter for Android        0.860158       0.125582        0.014260   \n",
      "24            Twitter Web App        0.254141       0.580629        0.165230   \n",
      "25                 SocialFlow        0.020328       0.804300        0.175372   \n",
      "26            Twitter Web App        0.018727       0.705579        0.275694   \n",
      "27            Twitter Web App        0.398982       0.562495        0.038523   \n",
      "28            Twitter Web App        0.058654       0.629830        0.311515   \n",
      "29              WordPress.com        0.151100       0.797811        0.051089   \n",
      "\n",
      "   net_score  \n",
      "0   Positive  \n",
      "1    Neutral  \n",
      "2    Neutral  \n",
      "3    Neutral  \n",
      "4   Negative  \n",
      "5    Neutral  \n",
      "6   Negative  \n",
      "7   Negative  \n",
      "8   Negative  \n",
      "9   Negative  \n",
      "10  Negative  \n",
      "11  Negative  \n",
      "12   Neutral  \n",
      "13  Negative  \n",
      "14  Negative  \n",
      "15  Negative  \n",
      "16  Negative  \n",
      "17   Neutral  \n",
      "18  Negative  \n",
      "19   Neutral  \n",
      "20   Neutral  \n",
      "21  Negative  \n",
      "22   Neutral  \n",
      "23  Negative  \n",
      "24   Neutral  \n",
      "25   Neutral  \n",
      "26   Neutral  \n",
      "27   Neutral  \n",
      "28   Neutral  \n",
      "29   Neutral  \n"
     ]
    }
   ],
   "source": [
    "# Sentiment analysis and output of sentiment analysis to file\n",
    "\n",
    "# Import modules\n",
    "import json, re, sys, os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "# Add custom directory to path\n",
    "sys.path.append(os.path.abspath(\"../py/\"))\n",
    "# Import script from directory\n",
    "import twit_data_scraper\n",
    "\n",
    "def process_text_textblob(text):\n",
    "    '''\n",
    "    Clean text for sentiment analysis\n",
    "    Dependencies - None\n",
    "    '''\n",
    "    print('Cleaning text (for TextBlob)')\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text)\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    text = re.sub(r'RT[\\s]+', '', text)\n",
    "    print('Text cleaned')\n",
    "    return text\n",
    "\n",
    "def roberta_load():\n",
    "    '''\n",
    "    Load sentiment analysis model - Roberta\n",
    "    Dependencies - None\n",
    "    '''\n",
    "    # load model and tokenizer\n",
    "    print(\"Loading Roberta and autokenizer.\")\n",
    "    roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "    model_params = [model, tokenizer]\n",
    "    print(\"Roberta and autotokenizer loaded.\")\n",
    "    return model_params\n",
    "\n",
    "def roberta_sent_score(df, col_name, model, tokenizer,data_path):\n",
    "    '''\n",
    "    Calculate sentiment scores and write them to text file\n",
    "    Dependencies - roberta_load (called from main)\n",
    "    '''\n",
    "    print(\"Calculating and recording tweet sentiment score.\")\n",
    "    counter = 0\n",
    "    # Clean tweet text\n",
    "    def clean_text(tweet):\n",
    "        '''\n",
    "        Clean tweet text\n",
    "        Dependencies - None\n",
    "        '''\n",
    "        tweet_words=[]\n",
    "        for word in tweet.split(' '):\n",
    "            if word.startswith('@') and len(word) > 1:\n",
    "                word = '@user'\n",
    "            elif word.startswith('http'):\n",
    "                word = \"http\"\n",
    "            tweet_words.append(word)\n",
    "        tweet_proc = \" \".join(tweet_words)\n",
    "        return tweet_proc\n",
    "    # Calculate tweet sentiment score and write to file with identifier tweet_id\n",
    "    for i in range(len(df)):\n",
    "        score_line = {}\n",
    "        tweet_id = df['tweet_id'][i]\n",
    "        tweet = df[col_name][i]\n",
    "        tweet_proc = clean_text(tweet)\n",
    "        # sentiment analysis\n",
    "        labels = ['negative_score', 'neutral_score', 'positive_score']\n",
    "        encoded_tweet = tokenizer(tweet_proc, return_tensors='pt')\n",
    "        output = model(**encoded_tweet)\n",
    "        score = output[0][0].detach().numpy()\n",
    "        score = softmax(score)\n",
    "        score_line = {'tweet_id':str(tweet_id), labels[0]:str(score[0]), \n",
    "                      labels[1]:str(score[1]), labels[2]:str(score[2])}\n",
    "        print(score_line)\n",
    "        # Write calculated scores to file\n",
    "        with open(data_path,'a+') as fhandle:\n",
    "            json.dump(score_line, fhandle)\n",
    "            fhandle.write(\"\\n\")\n",
    "        counter += 1\n",
    "#         if counter >= 10:\n",
    "#             break\n",
    "    print(\"Tweet sentiment score calculated and recorded.\")\n",
    "    return 0\n",
    "\n",
    "def senti_comparison(x):\n",
    "    '''\n",
    "    Compare values of negative, neutral and positive emotions and return the dominant emotion\n",
    "    Dependencies - None\n",
    "    '''\n",
    "    if (x['negative_score'] > x['neutral_score'] and \n",
    "    x['negative_score'] > x['positive_score']):\n",
    "        result = 'Negative'\n",
    "    elif (x['positive_score'] > x['neutral_score'] and \n",
    "    x['positive_score'] > x['negative_score']):\n",
    "        result = 'Positive'\n",
    "    elif (x['neutral_score'] > x['negative_score'] and \n",
    "    x['neutral_score'] > x['positive_score']):\n",
    "        result = 'Neutral'\n",
    "    else:\n",
    "        result = 'Undecided'\n",
    "    return result\n",
    "\n",
    "def df_types(df):\n",
    "    '''\n",
    "    Explicitly describe data type in dataframe\n",
    "    Needed for automatic data summary scripts\n",
    "    Dependencies - None\n",
    "    '''\n",
    "    pass\n",
    "    \n",
    "def file_path(rel_path, data_file):\n",
    "    '''\n",
    "    Form paths using os library and user inputs\n",
    "    Dependencies - None\n",
    "    '''\n",
    "    # Create path to data files\n",
    "    print(\"Generating data file path.\")\n",
    "    data_dir = os.path.abspath(rel_path)\n",
    "    data_path = os.path.join(data_dir,data_file)\n",
    "    print('File path generation completed.')\n",
    "    return data_path\n",
    "    \n",
    "\n",
    "def main():\n",
    "    inpt_fname = 'test.jsonuk'\n",
    "    otpt_fname = 'test_sentiment.jsonuk'\n",
    "    merged_fname = 'test_with_sentiments.json'\n",
    "    data_path = file_path(\"data/\",inpt_fname)\n",
    "    print(data_path)\n",
    "    #Initialize model and tokenizer\n",
    "    model, tokenizer = roberta_load()\n",
    "    # Read data into pandas dataframe based on file format\n",
    "    if inpt_fname.split('.')[1] == 'jsonuk':\n",
    "        df=twit_data_scraper.tweetfile_2_dataframe(data_path)\n",
    "    elif inpt_fname.split('.')[1] == 'csv':\n",
    "        df=pd.read_csv(data_path)\n",
    "    data_path = file_path(\"data/\",otpt_fname)\n",
    "    roberta_sent_score(df,'tweet_text', model, tokenizer,data_path = data_path)\n",
    "    print(data_path)\n",
    "    df2 = twit_data_scraper.tweetfile_2_dataframe(data_path)\n",
    "    df['tweet_id'] =  df['tweet_id'].astype(str)\n",
    "    # Merge data frames\n",
    "    df3=pd.merge(df,df2,how='left',on='tweet_id')\n",
    "    # Determin overall sentiment and add it to data frame\n",
    "    df3['net_score']=df3.apply(senti_comparison, axis = 1)\n",
    "    # Write merged data frame to file\n",
    "    df3.to_json(file_path(\"data/\", merged_fname))\n",
    "    df4 = pd.read_json(file_path(\"data/\", merged_fname))\n",
    "    print('----------------------------------------')\n",
    "    print(df4)\n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Twitter-Exp",
   "language": "python",
   "name": "twitter-exp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
