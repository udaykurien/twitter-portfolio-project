{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93e7be7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting tweet retrieval.\n",
      "Starting authentication.\n",
      "Authentication complete.\n",
      "Tweet retrieval complete.0.0%\n",
      "Starting write to file, data/test.\n",
      "Write to file, data/test, completed.\n",
      "Converting file to dataframe.\n",
      "File to dataframe conversion completed.\n",
      "               tweet_id                                         tweet_text  \\\n",
      "0   1567151913602269184  https://t.co/OuIxTYJjsQ\\nAlways good to get im...   \n",
      "1   1567151655560388608  ü©∏ After Roe v. Wade was overturned, US women s...   \n",
      "2   1567151271232110594  With the overturning of Roe v Wade we will be ...   \n",
      "3   1567150906902208513  Pro-Lifers cite Christianity to explain anti-a...   \n",
      "4   1567150877508501505  The United States is a global outlier for abor...   \n",
      "5   1567150757828329477  Since the U.S. Supreme Court overturn Roe v. W...   \n",
      "6   1567150677910032385  If you were a known abortionist before ‚ÄúRoe,‚Äù ...   \n",
      "7   1567150668057559041  \"I‚Äôm a law professor and even I am struggling ...   \n",
      "8   1567150667013267458  \"I‚Äôm a law professor and even I am struggling ...   \n",
      "9   1567150665364824066  \"I‚Äôm a law professor and even I am struggling ...   \n",
      "10  1567150665339633664  \"I‚Äôm a law professor and even I am struggling ...   \n",
      "11  1567150665297805314  \"I‚Äôm a law professor and even I am struggling ...   \n",
      "12  1567149608316407808  This summer, thousands turned up with @DSACinc...   \n",
      "13  1567148111935713282  A new survey from the Pew Research Center find...   \n",
      "14  1567147811392884736  ECTOPIC  PREGNANCY \\nthanks to the Hawleys who...   \n",
      "15  1567146990550532104  Jennifer Lawrence on Roe v Wade Overturn: Poli...   \n",
      "16  1567145952015695879  Jennifer Lawrence Blasts Two-Party System Amid...   \n",
      "17  1567145616462995459  Y‚Äôa une meuf sur TT qui raconte comment √† l‚Äôau...   \n",
      "18  1567144139447308290  Moral entrepreneurs changing laws reminds me o...   \n",
      "19  1567144048120532992  Democrats have over-performed in every special...   \n",
      "20  1567143772223406083  New: @JoshShapiroPA‚Äôs campaign released two ne...   \n",
      "21  1567143199285592064  US President Joe Biden signs order on abortion...   \n",
      "22  1567142933467365379  Top story: Jennifer Lawrence Talks Motherhood,...   \n",
      "23  1567142181210853377  To ALL Americans:\\nInflation, jobs, Roe v Wade...   \n",
      "24  1567141748966555651  The GOP has made it crystal clear: Overturning...   \n",
      "25  1567140890661064705  In a no-hold‚Äôs-barred interview for Vogue‚Äôs Oc...   \n",
      "26  1567140528252125186  Loving Jesus Style: Roe v Wade What Now https:...   \n",
      "27  1567140182708699138  [Premiering 9/6 at 1PM ET] Establishment Democ...   \n",
      "28  1567140139956043776  Loving Jesus Style: Roe v Wade   Winners? Lose...   \n",
      "29  1567140035899580416  Roe v. Wade has been gone for only a matter of...   \n",
      "\n",
      "                   tweet_time      tweet_author_id tweet_language  \\\n",
      "0   2022-09-06 14:05:07+00:00            724633794             en   \n",
      "1   2022-09-06 14:04:05+00:00            252751061             en   \n",
      "2   2022-09-06 14:02:33+00:00             28863408             en   \n",
      "3   2022-09-06 14:01:07+00:00  1329506226900754434             en   \n",
      "4   2022-09-06 14:01:00+00:00  1109933379217252353             en   \n",
      "5   2022-09-06 14:00:31+00:00             14437914             en   \n",
      "6   2022-09-06 14:00:12+00:00             82689705             en   \n",
      "7   2022-09-06 14:00:10+00:00             24878216             en   \n",
      "8   2022-09-06 14:00:09+00:00             10685542             en   \n",
      "9   2022-09-06 14:00:09+00:00           2149414262             en   \n",
      "10  2022-09-06 14:00:09+00:00             18169582             en   \n",
      "11  2022-09-06 14:00:09+00:00             14095883             en   \n",
      "12  2022-09-06 13:55:57+00:00   821892571576279040             en   \n",
      "13  2022-09-06 13:50:00+00:00             20545835             en   \n",
      "14  2022-09-06 13:48:49+00:00   875324076230922242             en   \n",
      "15  2022-09-06 13:45:33+00:00            198306835             en   \n",
      "16  2022-09-06 13:41:25+00:00             13992132             en   \n",
      "17  2022-09-06 13:40:05+00:00           2778227002             fr   \n",
      "18  2022-09-06 13:34:13+00:00  1481062557729312772             en   \n",
      "19  2022-09-06 13:33:51+00:00  1087380412089987077             en   \n",
      "20  2022-09-06 13:32:46+00:00            307885277             en   \n",
      "21  2022-09-06 13:30:29+00:00  1548014239884816387             en   \n",
      "22  2022-09-06 13:29:26+00:00           1276324501             en   \n",
      "23  2022-09-06 13:26:26+00:00             50502359             en   \n",
      "24  2022-09-06 13:24:43+00:00  1484313372934156290             en   \n",
      "25  2022-09-06 13:21:19+00:00            136361303             en   \n",
      "26  2022-09-06 13:19:52+00:00           1519990998             en   \n",
      "27  2022-09-06 13:18:30+00:00  1557070082496405504             en   \n",
      "28  2022-09-06 13:18:20+00:00           1519990998             en   \n",
      "29  2022-09-06 13:17:55+00:00  1557648186319048704             en   \n",
      "\n",
      "    retweet_count  reply_count  like_count  quote_count  \\\n",
      "0               0            0           0            0   \n",
      "1               1            0           1            0   \n",
      "2               0            0           0            0   \n",
      "3               0            0           0            0   \n",
      "4               0            0           0            0   \n",
      "5               0            0           7            1   \n",
      "6               0            0           0            0   \n",
      "7               0            0           0            0   \n",
      "8               0            0           1            0   \n",
      "9               0            0           0            0   \n",
      "10              0            0           0            0   \n",
      "11              0            0           0            0   \n",
      "12              2            0           2            0   \n",
      "13              2           36          18            2   \n",
      "14              0            0           0            0   \n",
      "15              0            0           0            0   \n",
      "16              0            0          47            5   \n",
      "17              0            0           0            0   \n",
      "18              0            0           0            0   \n",
      "19             18           41          68           10   \n",
      "20             10            0          20            0   \n",
      "21              0            0           0            0   \n",
      "22              0            0           0            0   \n",
      "23              0            0           0            0   \n",
      "24              0            0           0            0   \n",
      "25             23            2         161            4   \n",
      "26              0            0           0            0   \n",
      "27              0            0           0            0   \n",
      "28              0            0           0            0   \n",
      "29              0            0           0            0   \n",
      "\n",
      "                 tweet_source  \n",
      "0             Twitter Web App  \n",
      "1                  SocialFlow  \n",
      "2          Twitter for iPhone  \n",
      "3                  Zapier.com  \n",
      "4   Semrush Social Media Tool  \n",
      "5               Sprout Social  \n",
      "6                     Echobox  \n",
      "7              SocialNewsDesk  \n",
      "8              SocialNewsDesk  \n",
      "9              SocialNewsDesk  \n",
      "10             SocialNewsDesk  \n",
      "11             SocialNewsDesk  \n",
      "12         Twitter for iPhone  \n",
      "13                    Emplifi  \n",
      "14            Twitter Web App  \n",
      "15              WordPress.com  \n",
      "16            Twitter Web App  \n",
      "17         Twitter for iPhone  \n",
      "18         Twitter for iPhone  \n",
      "19       Twitter Media Studio  \n",
      "20         Twitter for iPhone  \n",
      "21            Twitter Web App  \n",
      "22          The Tweeted Times  \n",
      "23        Twitter for Android  \n",
      "24            Twitter Web App  \n",
      "25                 SocialFlow  \n",
      "26            Twitter Web App  \n",
      "27            Twitter Web App  \n",
      "28            Twitter Web App  \n",
      "29              WordPress.com  \n"
     ]
    }
   ],
   "source": [
    "import tweepy, twit_auth_cred, os, json, time\n",
    "import pandas as pd\n",
    "\n",
    "def twit_client():\n",
    "    ''' \n",
    "    Authenticate and create instance of twitter client.\n",
    "    '''\n",
    "    print(\"Starting authentication.\")\n",
    "    client = tweepy.Client(\n",
    "        bearer_token = twit_auth_cred.bearer_token,\n",
    "        consumer_key = twit_auth_cred.api_key,\n",
    "        consumer_secret = twit_auth_cred.api_key_secret,\n",
    "        access_token = twit_auth_cred.access_token,\n",
    "        access_token_secret = twit_auth_cred.access_token_secret,\n",
    "    )\n",
    "    print(\"Authentication complete.\")\n",
    "    return client\n",
    "\n",
    "def get_user_info(lst_author_id):\n",
    "    '''\n",
    "    Get twitter usernames corresponding to their user ids.\n",
    "    '''\n",
    "    client = twit_client()\n",
    "    user_name = []\n",
    "    for author_id in lst_author_id:\n",
    "        user_name.append(client.get_user(author_id = author_id))\n",
    "    return user\n",
    "\n",
    "def search_tweets(str_query, int_max_results, list_expansions, list_tweet_fields, \n",
    "                  list_user_fields,paginator_limit):\n",
    "    '''\n",
    "    Scrape tweets based on certain filters and parameters.\n",
    "    '''\n",
    "    print(\"Starting tweet retrieval.\")\n",
    "    paginator = tweepy.Paginator\n",
    "    client = twit_client()\n",
    "    search_results = []\n",
    "    counter = 0\n",
    "    for iterator in paginator(client.search_recent_tweets,\n",
    "                              query = str_query, \n",
    "                              max_results = int_max_results,\n",
    "                              expansions = list_expansions,\n",
    "                              tweet_fields = list_tweet_fields,\n",
    "                              user_fields = list_user_fields).flatten(\n",
    "                              limit = paginator_limit):\n",
    "        counter += 1   \n",
    "        print(\"Retrieval loop number: {number}%\".format(\n",
    "            number = round((counter/paginator_limit)*100,2)),end='',flush=True)        \n",
    "#         time.sleep(0.3)\n",
    "        search_results.append(iterator)\n",
    "        print('\\r', end='')\n",
    "    print('\\r', end='')\n",
    "    print(\"Tweet retrieval complete.\")\n",
    "#     print(search_results)\n",
    "    return search_results\n",
    "\n",
    "def tweets_to_file(data_file, search_results):\n",
    "    '''\n",
    "    Save tweets to file using a custom json/dictionary type format.\n",
    "    '''\n",
    "    print(\"Starting write to file, {data_file}.\".format(data_file=data_file))\n",
    "    with open(data_file,'w') as fhandle:\n",
    "        for tweet in search_results:\n",
    "            tmp_dict  = {\n",
    "                \"tweet_id\" : tweet.id,\n",
    "                \"tweet_text\" : tweet.text,\n",
    "                \"tweet_time\" : str(tweet.created_at),\n",
    "                \"tweet_author_id\" : tweet.author_id,\n",
    "#                 \"tweet_username\" : tweet.username,\n",
    "                \"tweet_language\" : tweet.lang,\n",
    "                \"tweet_public_metrics\" : tweet.public_metrics,\n",
    "                \"tweet_source\" : tweet.source\n",
    "            }\n",
    "            json.dump(tmp_dict, fhandle)\n",
    "            fhandle.write(\"\\n\")\n",
    "    print(\"Write to file, {data_file}, completed.\".format(data_file=data_file))\n",
    "    return 0\n",
    "\n",
    "def tweetfile_2_dataframe(data_file):\n",
    "    '''\n",
    "    Import custom json data file into dataframe.\n",
    "    '''\n",
    "    print(\"Converting file to dataframe.\")\n",
    "    with open(data_file, 'r') as fhandle:\n",
    "        lines = fhandle.readlines()\n",
    "        dict_lst = []   \n",
    "        for line in lines:\n",
    "            organized_dict = {}\n",
    "            tmp_dict = json.loads(line.strip())\n",
    "            for key in tmp_dict:\n",
    "                if key == 'tweet_public_metrics':\n",
    "                    for key2 in tmp_dict['tweet_public_metrics']:\n",
    "                        organized_dict[key2] = tmp_dict['tweet_public_metrics'][key2]\n",
    "                else:\n",
    "                    organized_dict[key] = tmp_dict[key]\n",
    "            dict_lst.append(organized_dict)\n",
    "    df = pd.DataFrame(dict_lst)\n",
    "    print(\"File to dataframe conversion completed.\")\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # Application Options\n",
    "    fetch_new_data = 'y' # value 'y' for yes\n",
    "    write_data_to_file = 'y'\n",
    "    read_from_file = 'y' # value 'y' for yes\n",
    "    f_path = 'data'\n",
    "    f_name = 'test'\n",
    "    data_file = os.path.join(f_path,f_name)\n",
    "    # Fetch new data\n",
    "    if fetch_new_data == 'y':\n",
    "        # Parameters\n",
    "        str_query_1 = '((Roe Wade) OR (roe wade)) -is:retweet -is:reply -is:quote'\n",
    "        int_max_results = 20\n",
    "        list_expansions = ['author_id','entities.mentions.username'] \n",
    "        list_tweet_fields = ['created_at','lang','public_metrics', 'source','id']\n",
    "        list_user_fields = ['username']\n",
    "        paginator_limit = 30\n",
    "        # Retrieve tweets as a list\n",
    "        search_results = search_tweets(\n",
    "            str_query_1, \n",
    "            int_max_results, \n",
    "            list_expansions, \n",
    "            list_tweet_fields,\n",
    "            list_user_fields,\n",
    "            paginator_limit\n",
    "        )\n",
    "        # Write tweet data to file\n",
    "    if write_data_to_file == 'y':\n",
    "        tweets_to_file(data_file, search_results)\n",
    "    # Read data from file\n",
    "    if read_from_file == 'y':\n",
    "        # Import file as pandas data frame\n",
    "        df = tweetfile_2_dataframe(data_file)\n",
    "        print(df)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Twitter-Exp",
   "language": "python",
   "name": "twitter-exp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
